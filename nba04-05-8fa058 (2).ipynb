{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandasql as psql\n\n# read in csv file into dataframe using pandas\ndf_team = pd.read_csv(\"../input/nbaplayoffseasonaldata/team_season.txt\",header=0)\ndf_player_regular = pd.read_csv(\"../input/nbaplayoffseasonaldata/player_regular_season.txt\",header=0) \ndf_player_playoff = pd.read_csv(\"../input/nbaplayoffseasonaldata/player_playoffs.txt\",header=0)\ndf_player_allstar = pd.read_csv(\"../input/nbaplayoffseasonaldata/player_allstar.txt\",header=0)\n\ndf_team_info = pd.read_csv(\"../input/nbaplayoffseasonaldata/teams.txt\")\ny = pd.read_csv(\"/kaggle/input/new-ylabel/new_y.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get required 2002-2003 seasonal data\ndf_team_02_03 = df_team.loc[(df_team.year >= 2002) & (df_team.year <= 2003)]\ndf_team_02_03.loc[:,['team', 'year', 'o_pts', 'd_pts', 'won', 'lost']]\ndf_team_02_03_avg = psql.sqldf(\"select team, AVG(o_pts) as AVG_opts, AVG(d_pts) as AVG_dpts, avg(won) as AVG_won, AVG(lost) as AVG_lost from df_team_02_03 group by team\")\ndf_team_02_03_avg\ny\ny_train = y.iloc[:,1:-1].mean(axis=1)\ny_pred = y.iloc[:,-1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_team_03_04 = df_team.loc[df_team.year == 2004]\ndf_team_03_04.loc[:,['team', 'year', 'o_pts', 'd_pts', 'won', 'lost']]\ndf_team_03_04_avg = psql.sqldf(\"select team, AVG(o_pts) as AVG_opts, AVG(d_pts) as AVG_dpts, avg(won) as AVG_won, AVG(lost) as AVG_lost from df_team_03_04 group by team\")\ndf_team_03_04_avg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all star players in year 2002 and 2003\ndf_allstar = df_player_allstar.loc[(df_player_allstar.year >= 2002) & (df_player_allstar.year <= 2003)]\ndf_allstar.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Allstars = psql.sqldf(\"select DISTINCT ilkid, firstname, lastname from df_allstar group by lastname;\")\nprint(Allstars)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Player_team = psql.sqldf(\"select ilkid, year, firstname, lastname, team from df_player_playoff where year >= 2002 AND year<= 2003;\")\nPlayer_team","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_allstar_team = psql.sqldf(\"select distinct P.ilkid, P.firstname, P.lastname, P.team from Player_team as P JOIN Allstars as A ON UPPER(A.ilkid) = UPPER(P.ilkid) and P.lastname = A.lastname;\")\n\nNumberOfAllstarPlayer = psql.sqldf(\"select team, COUNT(team) as NumberOfAllstarPlayer from df_allstar_team group by team\")\n\n\nallstar_sum = psql.sqldf(\"select N.team, T.name, N.NumberOfAllstarPlayer from NumberOfAllstarPlayer as N INNER JOIN team_fullname as T on N.team = T.team\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = psql.sqldf(\"select a.*, NumberOfAllStarPlayer from df_team_02_03_avg as a left join allstar_sum as b on a.team=b.team\")\nX = X.fillna(0)\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = psql.sqldf(\"select a.*, NumberOfAllStarPlayer from df_team_03_04_avg as a left join allstar_sum as b on a.team=b.team\")\nX_test = X_test.fillna(0)\nX_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regular = psql.sqldf(\"select * from df_player_regular where year >= 2002 AND year<= 2003;\")\nplayoff = psql.sqldf(\"select * from df_player_playoff where year >= 2002 AND year<= 2003;\")\n\n# efficiency calculation formula from https://en.wikipedia.org/wiki/Efficiency_(basketball)\n\nregular_efficiency = psql.sqldf(\"SELECT team, ilkid, firstname, lastname, pts, (pts+oreb+dreb+asts+stl+blk-turnover-fgm-ftm)/gp as efficiency from regular group by ilkid order by efficiency desc\")\nplayoff_efficiency = psql.sqldf(\"SELECT team, ilkid, firstname, lastname, pts, (pts+oreb+dreb+asts+stl+blk-turnover-fgm-ftm)/gp as efficiency from playoff group by ilkid order by efficiency desc\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_regular = psql.sqldf(\"select * from df_player_regular where year == 2004;\")\ntest_playoff = psql.sqldf(\"select * from df_player_playoff where year == 2004;\")\n\n# efficiency calculation formula from https://en.wikipedia.org/wiki/Efficiency_(basketball)\n\ntest_regular_efficiency = psql.sqldf(\"SELECT team, ilkid, firstname, lastname, pts, (pts+oreb+dreb+asts+stl+blk-turnover-fgm-ftm)/gp as efficiency from test_regular group by ilkid order by efficiency desc\")\ntest_playoff_efficiency = psql.sqldf(\"SELECT team, ilkid, firstname, lastname, pts, (pts+oreb+dreb+asts+stl+blk-turnover-fgm-ftm)/gp as efficiency from test_playoff group by ilkid order by efficiency desc\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_efficiency = psql.sqldf(\"Select P.team, P.ilkid, P.firstname, P.lastname, (P.pts*0.7 + R.pts*0.3) as weighted_pts, (P.efficiency*0.7 + R.efficiency*0.3) as weighted_efficiency from regular_efficiency as R INNER JOIN playoff_efficiency as P on P.firstname=R.firstname and P.lastname=R.lastname order by weighted_efficiency desc limit 100;\")\n\ntotal_efficiency.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_total_efficiency = psql.sqldf(\"Select P.team, P.ilkid, P.firstname, P.lastname, (P.pts*0.7 + R.pts*0.3) as weighted_pts, (P.efficiency*0.7 + R.efficiency*0.3) as weighted_efficiency from test_regular_efficiency as R INNER JOIN test_playoff_efficiency as P on P.firstname=R.firstname and P.lastname=R.lastname order by weighted_efficiency desc limit 100;\")\n\ntest_total_efficiency.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pts = psql.sqldf(\"select weighted_pts, weighted_efficiency from total_efficiency;\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalization of value\n\nfrom sklearn import preprocessing\n\nx = pts.values #returns a numpy array \n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_efficiency = psql.sqldf(\"Select P.team, P.ilkid, P.firstname, P.lastname, (P.pts*0.7 + R.pts*0.3) as weighted_pts, (P.efficiency*0.7 + R.efficiency*0.3) as weighted_efficiency from regular_efficiency as R INNER JOIN playoff_efficiency as P on P.firstname=R.firstname and P.lastname=R.lastname order by weighted_efficiency desc;\")\n\nX = psql.sqldf(\"select X.*, avg(T.weighted_pts) as AVG_weighted_pts, avg(T.weighted_efficiency) as AVG_weighted_efficiency from X left join total_efficiency as T on X.team = T.team GROUP BY X.team\")\nX_train = X.fillna(0)\n\nX_train.iloc[:,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = psql.sqldf(\"select X_test.*, avg(T.weighted_pts) as AVG_weighted_pts, avg(T.weighted_efficiency) as AVG_weighted_efficiency from X_test left join total_efficiency as T on X_test.team = T.team GROUP BY X_test.team\")\nX_test = X_test.fillna(0)\nX_test_scale = X_test.iloc[:,1:]\nX_test.iloc[:,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\nX_test_scale = min_max_scaler.fit_transform(X_test_scale)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly = PolynomialFeatures(degree=1)\nX_ = poly.fit_transform(X_train.iloc[:,1:])\nX_test = poly.fit_transform(X_test.iloc[:,1:])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate\nlg = LinearRegression()\n\n# Fit\nlg.fit(X_, y_train)\n\ny_pred = lg.predict(X_test)\n\nnp.argsort(-1 * y_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}